{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wp6u2WFB6sD3"
   },
   "source": [
    "# Python Libraries\n",
    "\n",
    "For this tutorial, we are going to explore the python libraries that include functionality that corresponds with the material discussed in the course.\n",
    "\n",
    "The primary package we will be using is:\n",
    "\n",
    "* **Statsmodels:** a library that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, exploring data, and constructing models.  \n",
    "\n",
    "*__ATTN__: If you are not familiar with the following packages:*  \n",
    "\n",
    "* **Numpy** is a library for working with arrays of data.  \n",
    "\n",
    "* **Pandas** is a library for data management, manipulation, and analysis.  \n",
    "\n",
    "* **Matplotlib** is a library for making visualizations.  \n",
    "\n",
    "* **Seaborn** is a higher-level interface to Matplotlib that can be used to simplify many visualization tasks.  \n",
    "\n",
    "We recommend you check out the first and second courses of the Statistics with Python specialization, **Understanding and Visualizing Data** and **Inferential Statistical Analysis with Python**.\n",
    "\n",
    "*__Important__: While this notebooks provides insight into the basics of these libraries,  it is recommended that you dig into the documentation available online.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bS09niUH6sD4"
   },
   "source": [
    "## StatsModels\n",
    "\n",
    "The StatsModels library is extremely extensive and includes functionality ranging from statistical methods to advanced topics such as regression, time-series analysis, and multivariate statistics.\n",
    "\n",
    "We will mainly be looking at the stats, OLS, and GLM sub-libraries.  However, we will begin by reviewing some functionality that has been referenced in earlier course of the Statistics with Python specialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAmQwUrM6sD4"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHW550yS6sD9"
   },
   "source": [
    "### Stats\n",
    "\n",
    "#### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0Diw1p66sD-",
    "outputId": "38a8e936-209c-49de-d828-7dae305acaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<statsmodels.stats.weightstats.DescrStatsW object at 0x0000013F1697BEB0>\n"
     ]
    }
   ],
   "source": [
    "# Draw random variables from a normal distribution with numpy\n",
    "normalRandomVariables = np.random.normal(0,1, 1000)\n",
    "\n",
    "# Create object that has descriptive statistics as variables\n",
    "x = sm.stats.DescrStatsW(normalRandomVariables)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3VPrgBO6sEC"
   },
   "source": [
    "As you can see from the above output, we have created an object with type: \"statsmodels.stats.weightstats.DescrStatsW\".  \n",
    "\n",
    "This object stores various descriptive statistics such as mean, standard deviation, variance, ect. that we can access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t080a6ZB6sEE",
    "outputId": "b275eed9-d036-4212-bfcc-0c8a3c72f89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.020815098602874685\n",
      "0.9899975259515813\n",
      "0.9800951013902519\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "print(x.mean)\n",
    "\n",
    "# Standard deviation\n",
    "print(x.std)\n",
    "\n",
    "# Variance\n",
    "print(x.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvveuP5x6sEH"
   },
   "source": [
    "The output above shows the mean, standard deviation, and variance of the 1000 random variables we drew from the distribution we generated above.\n",
    "\n",
    "There are other interesting things you can do with this object, such as generating confidence intervals and hypothesis testing.\n",
    "\n",
    "#### Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`proportion_confint` used to calculate the confidence interval for a proportion or a binary outcome\n",
    "```python\n",
    "# Syntax:\n",
    "lower, upper = proportion_confint(count, nobs, alpha=0.05, method='normal')\n",
    "```\n",
    "\n",
    "`zconfint_mean()` is used to calculate the confidence interval for the mean of a continuous variable\n",
    "```python\n",
    "# Syntax:\n",
    "lower, upper = zconfint_mean(x, std_mean, alpha=0.05)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B0pWYUHz6sEJ",
    "outputId": "eda277fe-cc28-44ba-c4d2-f667dd9846dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8227378265796143, 0.8772621734203857)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate confidence interval for a population proportion\n",
    "\n",
    "tstar = 1.96\n",
    "\n",
    "# Observer population proportion\n",
    "p = .85\n",
    "\n",
    "# Size of population\n",
    "n = 659\n",
    "\n",
    "# Construct confidence interval\n",
    "sm.stats.proportion_confint(n * p, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AuZGEYlG6sEM"
   },
   "source": [
    "The above output includes the lower and upper bounds of a 95% confidence interval of population proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwBfjY_y6sEN",
    "outputId": "475a8442-9cc0-4841-a8f3-0140583a8f6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76.57715593233026, 88.38284406766975)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import data that will be used to construct confidence interval of population mean\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/UMstatspy/UMStatsPy/master/Course_1/Cartwheeldata.csv\")\n",
    "\n",
    "# Generate confidence interval for a population mean\n",
    "sm.stats.DescrStatsW(df[\"CWDistance\"]).zconfint_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pk-nzwLg6sEP"
   },
   "source": [
    "The output above shows the lower and upper bounds of a 95% confidence interval of population mean.\n",
    "\n",
    "These functions should be familiar, if not, we recommend you take course 2 of our specialization.\n",
    "#### Hypothesis Testing\n",
    "`proportions_ztest` is used to test hypotheses and calculate p-values for proportions or proportions difference between two groups\n",
    "```python\n",
    "# Syntax:\n",
    "stat, pvalue = proportions_ztest(count, nobs, value=None, alternative='two-sided', prop_var=False)\n",
    "```\n",
    "\n",
    "`ztest` is used to test hypotheses and calculate p-values for means or mean differences between two groups\n",
    "\n",
    "```python\n",
    "stat, pvalue = ztest(x1, x2=None, value=0, alternative='two-sided', usevar='pooled', ddof=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aC6ZmdvT6sEQ",
    "outputId": "5f1243c9-34e5-4bda-9bda-1dfc8bc052b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.571067795759113, 0.010138547731721065)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One population proportion hypothesis testing\n",
    "\n",
    "# Population size\n",
    "n = 1018\n",
    "\n",
    "# Null hypothesis population proportion\n",
    "pnull = .52\n",
    "\n",
    "# Observe population proportion\n",
    "phat = .56\n",
    "\n",
    "# Calculate test statistic and p-value\n",
    "sm.stats.proportions_ztest(phat * n, n, pnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tdgO3pL6sEU",
    "outputId": "37a8fa49-ba7e-4996-e1e6-85b80b22383b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8234523266982029, 0.20512540845395266)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the dataframe imported above, perform a hypothesis test for population mean\n",
    "sm.stats.ztest(df[\"CWDistance\"], value = 80, alternative = \"larger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs above are the test statistics and p-values from the respective hypothesis tests.\n",
    "\n",
    "If you'd like to review these functions on your own, the stats sub-library documentation can be found at the following url: https://www.statsmodels.org/stable/stats.html\n",
    "\n",
    "This concludes the review portion of this notebook,  now we are going to introduce the OLS and GLM sub-libraries and the functions you will be seeing throughout this course.\n",
    "\n",
    "# OLS (Ordinary Least Squares), GLM (Generalized Linear Models), GEE (Generalize Estimated Equations), MIXEDLM (Multilevel Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method  | Definition                      | Use case                                            | Strengths                                            | Weaknesses                                             | Syntax (*`import statsmodels as sm`*)                              |\n",
    "|---------|---------------------------------|-----------------------------------------------------|------------------------------------------------------|--------------------------------------------------------|---------------------------------------------------|\n",
    "| OLS     | Ordinary Least Squares          | Fits a linear model to normally distributed data     | Simple, easy to understand and implement             | Not as flexible as GLM, not as robust to outliers      | `sm.OLS.from_formula(formula, data=df).fit()`     |\n",
    "| GLM     | Generalized Linear Model        | Fits a linear model to data with wider distributions | Flexible, robust to outliers, wider range of distributions | More complex than OLS, not ideal for normal data       | `sm.GLM.from_formula(formula, data=df).fit()`     |\n",
    "| GEE     | Generalized Estimating Equations | Fits a linear model to clustered data               | Accounts for clustering, improves prediction accuracy | More complex than OLS and GLM                          | `sm.GEE.from_formula(formula, groups=group_col, data=df).fit()` |\n",
    "| MIXEDLM | Mixed-effects Linear Model      | Fits a linear model to data with fixed and random effects | Accounts for fixed and random effects, improves prediction accuracy | More complex than OLS, GLM, GEE                   | `sm.MixedLM.from_formula(formula, data=df).fit()` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ko78IcAX6sEX"
   },
   "source": [
    "The OLS, GLM, GEE, and MIXEDLM sub-libraries are the primary libraries in statsmodels that we will be utilizing in this course to create various models.\n",
    "\n",
    "Below, we will give a brief description of each model and a skeleton of the functions you will see going forward in the course.  This is simply for you to get familiar with these concepts and to prepare you for the coming weeks.  If their application at this time seems a bit ambigious have no fear as they will be discussed in detail throughout this course!\n",
    "\n",
    "For each of the following models, we follow our similar structure which means we will be following our structure of Dependent and Independent Variables, with a few caveats that will be expressed below.\n",
    "\n",
    "#### Ordinary Least Squares\n",
    "\n",
    "Ordinary Least Squares is a method for estimating the unknown parameters in a linear regression model.  This is the function we will use when our target variable is continuous. \n",
    "\n",
    "(Bonus) OLS is a linear regression method used to estimate the relationship between a dependent variable and one or more independent variables. It assumes that the relationship is linear and that the errors are normally distributed and have constant variance. OLS minimizes the sum of squared differences between the observed and predicted values to obtain the best-fitting regression line. OLS is commonly used in various fields for predictive modeling and causal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhalCiu-6sEX",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>BPXSY1</td>      <th>  R-squared:         </th> <td>   0.215</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.214</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   697.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 23 Jul 2023</td> <th>  Prob (F-statistic):</th> <td>1.87e-268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:09:07</td>     <th>  Log-Likelihood:    </th> <td> -21505.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5102</td>      <th>  AIC:               </th> <td>4.302e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5099</td>      <th>  BIC:               </th> <td>4.304e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>  100.6305</td> <td>    0.712</td> <td>  141.257</td> <td> 0.000</td> <td>   99.234</td> <td>  102.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th> <td>    3.2322</td> <td>    0.459</td> <td>    7.040</td> <td> 0.000</td> <td>    2.332</td> <td>    4.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIDAGEYR</th>          <td>    0.4739</td> <td>    0.013</td> <td>   36.518</td> <td> 0.000</td> <td>    0.448</td> <td>    0.499</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>706.732</td> <th>  Durbin-Watson:     </th> <td>   2.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1582.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.818</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.184</td>  <th>  Cond. No.          </th> <td>    168.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 BPXSY1   R-squared:                       0.215\n",
       "Model:                            OLS   Adj. R-squared:                  0.214\n",
       "Method:                 Least Squares   F-statistic:                     697.4\n",
       "Date:                Sun, 23 Jul 2023   Prob (F-statistic):          1.87e-268\n",
       "Time:                        23:09:07   Log-Likelihood:                -21505.\n",
       "No. Observations:                5102   AIC:                         4.302e+04\n",
       "Df Residuals:                    5099   BIC:                         4.304e+04\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept           100.6305      0.712    141.257      0.000      99.234     102.027\n",
       "RIAGENDRx[T.Male]     3.2322      0.459      7.040      0.000       2.332       4.132\n",
       "RIDAGEYR              0.4739      0.013     36.518      0.000       0.448       0.499\n",
       "==============================================================================\n",
       "Omnibus:                      706.732   Durbin-Watson:                   2.036\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1582.730\n",
       "Skew:                           0.818   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.184   Cond. No.                         168.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = pd.read_csv(\"nhanes_2015_2016.csv\")\n",
    "\n",
    "# Drop unused columns, drop rows with any missing values.\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\",\n",
    "        \"SMQ020\", \"SDMVSTRA\", \"SDMVPSU\"]\n",
    "da = da[vars].dropna()\n",
    "\n",
    "da[\"RIAGENDRx\"] = da.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})\n",
    "\n",
    "model = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx\", data=da)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujGjtQwR6sEa"
   },
   "source": [
    "The above code is creating a multiple linear regression where the target variable is BPXSY1 and the two predictor variables are RIDAGEYR and RIAGENDRx.\n",
    "\n",
    "Note that the target variable, BPXSY1, is a continous variable that represents blood pressure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: `from sklearn.linear_model import LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 107.09494236237379\n",
      "Coefficients: [ 0.47389682 -3.23224502]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the data and drop unused columns and rows with missing values\n",
    "da = pd.read_csv(\"nhanes_2015_2016.csv\")\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\", \"SMQ020\", \"SDMVSTRA\", \"SDMVPSU\"]\n",
    "da = da[vars].dropna()\n",
    "\n",
    "# Prepare the data for modeling\n",
    "X = da[[\"RIDAGEYR\", \"RIAGENDR\"]]  # Independent variables\n",
    "y = da[\"BPXSY1\"]                  # Dependent variable\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"Coefficients:\", model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7mrqEjx6sEb"
   },
   "source": [
    "#### Generalized Linear Models\n",
    "\n",
    "While generalized linear models are a broad topic, **in this course we will be using this suite of functions to carry out logistic regression.**  Logistic regression is used when our target variable is a binary outcome, or a classification of two groups, which can be denoted as group 0 and group 1.\n",
    "\n",
    "(Bonus)\n",
    "GLM is an extension of linear regression that allows for modeling relationships between dependent and independent variables when the response variable follows a distribution other than the normal distribution. GLM includes different types of regression models, such as \n",
    "- logistic regression for binary outcomes, \n",
    "- Poisson regression for count data, and \n",
    "- gamma regression for skewed continuous data. \n",
    "\n",
    "GLM incorporates a link function that relates the linear predictor to the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "66gX6Ivv6sEb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>smq</td>       <th>  No. Observations:  </th>  <td>  5094</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  5092</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -3350.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 23 Jul 2023</td> <th>  Deviance:          </th> <td>  6701.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:10:53</td>     <th>  Pearson chi2:      </th> <td>5.09e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>4</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.04557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>   -0.7547</td> <td>    0.042</td> <td>  -18.071</td> <td> 0.000</td> <td>   -0.837</td> <td>   -0.673</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th> <td>    0.8851</td> <td>    0.058</td> <td>   15.227</td> <td> 0.000</td> <td>    0.771</td> <td>    0.999</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                    smq   No. Observations:                 5094\n",
       "Model:                            GLM   Df Residuals:                     5092\n",
       "Model Family:                Binomial   Df Model:                            1\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -3350.6\n",
       "Date:                Sun, 23 Jul 2023   Deviance:                       6701.2\n",
       "Time:                        23:10:53   Pearson chi2:                 5.09e+03\n",
       "No. Iterations:                     4   Pseudo R-squ. (CS):            0.04557\n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept            -0.7547      0.042    -18.071      0.000      -0.837      -0.673\n",
       "RIAGENDRx[T.Male]     0.8851      0.058     15.227      0.000       0.771       0.999\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da[\"smq\"] = da.SMQ020.replace({2: 0, 7: np.nan, 9: np.nan})\n",
    "model = sm.GLM.from_formula(\"smq ~ RIAGENDRx\", family=sm.families.Binomial(), data=da)\n",
    "res = model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAGWs0sA6sEg"
   },
   "source": [
    "Above is a example of creating a logistic model where the target value is SMQ020x, which in this case is whether or not this person is a smoker or not.  The predictor is RIAGENDRx, which is gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus `from sklearn.linear_model import LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 3.6567624630909252\n",
      "Coefficient(s): [-0.33794606]\n",
      "Accuracy: 0.6347\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare the data\n",
    "X = da[['RIAGENDR']]\n",
    "y = da['SMQ020']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print the intercept and coefficients\n",
    "intercept = model.intercept_[0]\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "print(f\"Intercept: {intercept}\")\n",
    "print(f\"Coefficient(s): {coefficients}\")\n",
    "\n",
    "# Print the accuracy score\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPr2J3Xu6sEh"
   },
   "source": [
    "#### Generalized Estimated Equations\n",
    "\n",
    "Generalized Estimating Equations estimate generalized linear models for panel, cluster or repeated measures data when the observations are possibly correlated within a cluster but uncorrelated across clusters.  These are used primarily when there is uncertainty regarding correlation between outcomes. \"Generalized Estimating Equations\" (GEE) fit marginal linear models, and estimate intraclass correlation.\n",
    "\n",
    "(Bonus): GEE is a method used for analyzing correlated or clustered data. It is an extension of GLM that accounts for within-cluster correlation by estimating population-averaged effects. GEE is commonly used in longitudinal and clustered data analysis where observations within the same cluster are expected to be more correlated than observations from different clusters. GEE provides robust parameter estimates and standard errors, allowing for valid inference even when the correlation structure is misspecified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2UPibR56sEi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The correlation between two observations in the same cluster is 0.030'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da[\"group\"] = 10*da.SDMVSTRA + da.SDMVPSU\n",
    "model = sm.GEE.from_formula(\"BPXSY1 ~ 1\", groups=\"group\", cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "res = model.fit()\n",
    "res.cov_struct.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI-wvJZz6sEm"
   },
   "source": [
    "Here we are creating a marginal linear model of BPXSY1 to determine the estimated ICC value, which would indicate whether or not there are correlated clusters of BPXSY1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTDJVIpQ6sEn"
   },
   "source": [
    "#### Multilevel Models\n",
    "\n",
    "Similarly to GEEs, we use multilevel models when there is potential for outcomes to be grouped together which is not uncommon when using various sampling methods to collect data.\n",
    "\n",
    "(Bonus) MIXEDLM (Mixed Effects Linear Model): MIXEDLM, also known as mixed-effects regression or hierarchical linear regression, is a method used to analyze data with both fixed effects (population-level effects) and random effects (subject-specific effects). It is used when there is nested or clustered data with repeated measures or when there are hierarchical structures in the data. MIXEDLM estimates the fixed and random effects simultaneously and can handle unbalanced and missing data. It is commonly used in social sciences, biology, and other fields where data have complex structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kx8UyI4b6sEo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPXSY1 The correlation between two observations in the same cluster is 0.030\n",
      "RIDAGEYR The correlation between two observations in the same cluster is 0.035\n",
      "BMXBMI The correlation between two observations in the same cluster is 0.039\n",
      "smq The correlation between two observations in the same cluster is 0.026\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.959\n"
     ]
    }
   ],
   "source": [
    "for v in [\"BPXSY1\", \"RIDAGEYR\", \"BMXBMI\", \"smq\", \"SDMVSTRA\"]:\n",
    "    model = sm.GEE.from_formula(v + \" ~ 1\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "    result = model.fit()\n",
    "    print(v, result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oCAM_2cf6sEt"
   },
   "source": [
    "What;s nice about the statsmodels library is that all the models follow the similar structure and syntax.  \n",
    "\n",
    "\n",
    "Documentation and examples of these models can be found at the following links:\n",
    "\n",
    "* OLS: https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html\n",
    "\n",
    "* GLM: https://www.statsmodels.org/stable/glm.html\n",
    "\n",
    "* GEE: https://www.statsmodels.org/stable/gee.html\n",
    "\n",
    "* MIXEDLM: https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html\n",
    "\n",
    "Feel free to read up on these sub-libraries and their use cases.  In week 2 you will see examples of OLS and GLM, where in week 3, we will be implementing GEE and MIXEDLM."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Important Python Libraries - Fitting Statistical Models to Data with Python.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
